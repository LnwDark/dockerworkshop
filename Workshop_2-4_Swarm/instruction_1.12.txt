For this workshop. We will create new docker-engine for swarm 1.2 with new architecture for demonstration below:

=================
Create docker-engine for LAB Swarm
=================
1. Check/Clean-Up all docker-machine on previous lab with command:

	
	docker-machine stop swarm-mng swarm-node1 swarm-node2 labdocker2
	docker-machine rm swarm-mng swarm-node1 swarm-node2 labdocker2


2. Create docker-engine for lab (for reduce resource consume) with command below:

	docker-machine create --driver=virtualbox --virtualbox-memory=600 swarm-mng
	docker-machine create --driver=virtualbox --virtualbox-memory=600 swarm-node1
	docker-machine create --driver=virtualbox --virtualbox-memory=600 swarm-node2
	docker-machine regenerate-certs swarm-mag swarm-node1 swarm-node2

3. Record ip address of each docker-engine for use in next step: Normally should like below:

D:\certs>docker-machine ls
NAME          ACTIVE   DRIVER       STATE     URL                         SWARM
labdocker     -        virtualbox   Running   tcp://192.168.99.100:2376           v1.12.0-rc4   
swarm-mng     -        virtualbox   Running   tcp://192.168.99.101:2376           v1.12.0-rc4   
swarm-node1   -        virtualbox   Running   tcp://192.168.99.102:2376           v1.12.0-rc4   
swarm-node2   -        virtualbox   Running   tcp://192.168.99.103:2376           v1.12.0-rc4


======================
Initial Swarm Cluster
======================
location: ####swarm-mng####

1. Login to docker-engine and pull image for consul by command: 

	docker swarm init --advertise-addr 192.168.99.101:2377

location: ####swarm-node1####

2. Join node to swarm by command:

	docker swarm join \
    --token SWMTKN-1-316tn4xze2w2zi7jpukxjdyoniu18k0onh5ywrxinzmau8t71f-4750wvm6fqxi8lbd3trlw7pk4 \
    192.168.99.101:2377



location: ####swarm-node2####
3. Join node to swarm by command:

	docker swarm join \
    --token SWMTKN-1-316tn4xze2w2zi7jpukxjdyoniu18k0onh5ywrxinzmau8t71f-4750wvm6fqxi8lbd3trlw7pk4 \
    192.168.99.101:2377

location: ####swarm-mng####
4. Check status of all node that join to swarm cluster by command:

	docker node ls

	

================
Initial Service on Docker Swarm
================
location: ####swarm-mng####

1. Initial docker service for nodes:

	docker service create --name nodejs \
	labdocker/alpineweb:latest node hello.js
2. Check process of container by command: 
	
	docker service ls
	docker service task nodes

3. Scale nodes by command: docker service scale nodejs=5

4. Check latest scale by command: docker service ls

5. Test update service name by command: 

	docker service update nodejs â€”name nodejsnew
	docker service ls
	docker service task nodejsnew

6. Update reserve/limit CPU by command:

	docker service update --reserve-cpu 2 --limit-cpu 3 nodejsnew
	docker service inspect nodejsnew|more

6. Stop & Remove service by command: docker service rm nodejsnew

===============
Container Scheduling: Affinity by Container Name/ID
===============
location: ####client-cli####

1. Run container with Affinity (Container Name) as command below:

	docker run -dt --name nodejs -e constraint:Storage==sas \
	labdocker/alpineweb:latest node hello.js
	
	docker run -dt --name web -e affinity:container==nodejs \
	labdocker/nginx:latest 
	
	docker ps

2. Clean Up by command

	docker stop nodejs web
	docker rm nodejs web


===============
Container Scheduling: Affinity by Image
===============
location: ####swarm-node1####

1. Pull Image for alpine linux on swarm-node1 by command: docker pull labdocker/alpine:latest

location: swarm-node2

2. Delete Image (If Avaliable) for alpine linux on swarm-node2 by command: docker rmi labdocker/alpine:latest

location: ####client-cli####

3. Run container with Affinity (Image) as commmand:

	docker run -dt --name node1 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node2 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node3 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node4 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node5 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node6 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node7 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node8 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker run -dt --name node9 -e affinity:image==labdocker/alpine:latest labdocker/alpine:latest sh
	docker ps

4. Clean Up by command

	docker stop node1 node2 node3 node4 node5 node6 node7 node8 node9

	docker rm node1 node2 node3 node4 node5 node6 node7 node8 node9

============
Container Scheduling: Dependency Filter
============
location: ####client-cli####

1. Create volume container by command: 

	docker run -dt --name datavol -v /data labdocker/alpine:latest sh

2. Run container for mount volume from specify above by command:

	docker run -dt --name web1 --volumes-from datavol labdocker/alpine sh
	docker ps

3. Clean Up by command:

	docker stop datavol web1
	docker rm -v datavol web1

============
Container Scheduling: Port Filter
============
location: ####client-cli####

1. Run docker container for create 2 container nodejs with mapping port 3000 by command:
	
	docker run -dt --name nodejs1 -p 3000:3000 labdocker/alpineweb:latest node hello.js
	docker run -dt --name nodejs2 -p 3000:3000 labdocker/alpineweb:latest node hello.js
	docker ps

2. Clean Up by command:

	docker stop nodejs1 nodejs2
	docker rm nodejs1 nodejs2

===========
SWARM High Avalibility
===========
location: ####swarm-mng####
1. Stop swarm-manager container by command:

	docker stop swarm-mng
	docker rm swarm-mng

2. Run docker container for swarm-mng with option for replication by command:

	docker run -dt --name swarm-mng --restart=unless-stopped -p 3375:2375 \
	swarm manage --replication --advertise 192.168.99.102:3375 \
	consul://192.168.99.100:8500

3. Check log for election the docker-manager by command: "docker logs swarm-mng"

Location: ####swarm-node1####

4. Run docker container for swarm-mng with option for replication by command:

	docker run -dt --name swarm-mng --restart=unless-stopped -p 3375:2375 \
	swarm manage --replication --advertise 192.168.99.103:3375 \
	consul://192.168.99.100:8500

5. Check log for election the docker-manager by command: "docker logs swarm-mng"

location: ####swarm-mng####

6. Stop swarm-manger container by command:"docker stop swarm-mng"

location: swarm-node1

7.  Check log for election the docker-manager by command: "docker logs swarm-mng"

location: ####client-cli####

8.  Test Connect to new swarm-mng by command:

	set/export DOCKER_HOST=192.168.99.103:3375
	docker info

9.  Clean Up all docker-machine by command:
location: ####client-cli####

===========
Create OverLay Network
===========
location: ####client-cli###

1. Check current network on swarm with command: docker network ls

2. Create new overlay network for swarm with command:

	docker network create --driver overlay --subnet=192.168.100.0/24 swarmnet
	docker network ls

3. Create 2 container on difference node for test overlay network with command:

	docker run -dt --name test1 --net=swarmnet -e=constraint:node==swarm-node1 labdocker/alpine sh
	docker run -dt --name test2 --net=swarmnet -e=constraint:node==swarm-node2 labdocker/alpine sh

4. Check IP Address of both container by command:

	docker inspect test1|grep IPAddress ==> 192.168.100.102
	docker inspect test2|grep IPAddress ==> 192.168.100.103

5. Test access from container "test1" and access to "test2" by command:

	docker exec -it test1 ping 192.168.100.3
	docker exec -it test2 ping 192.168.100.2

6. CleanUp Lab
	docker stop test1 test2
	docker rm test1 test2

===========
Reschedule Node Failure
===========
location: ####client-cli###
1. Run container with option "on-node-failure" by command:

	docker run -dt --name alpine -e reschedule:on-node-failure labdocker/alpine:latest sh

2. Check container avaliable on swarm by command: docker ps

3. Shutdown specific node: sudo shutdown -h now

4. Wait 5 min before check: docker ps

5. CleanUp Lab by command: 
	docker stop alpine
	docker rm alpine


==========
Clean Up Lab
==========
location: ####Your PC / Mac Book####
1. Stop/Remove all swarm node by command:

	docker-machine stop swarm-mng swarm-node1 swarm-node2
	docker-machine rm swarm-mng swarm-node1 swarm-node2

location: ####labdocker####
2. Stop consul container by command:

	docker stop consul
	docker rm console

